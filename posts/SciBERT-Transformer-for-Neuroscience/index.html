<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="SciBERT Transformer for Neuroscience" /><meta name="author" content="Mrunal" /><meta property="og:locale" content="en_US" /><meta name="description" content="Hugging Face Transformer model for Neuroscience JSON data" /><meta property="og:description" content="Hugging Face Transformer model for Neuroscience JSON data" /><link rel="canonical" href="https://gli-mrunal.github.io/posts/SciBERT-Transformer-for-Neuroscience/" /><meta property="og:url" content="https://gli-mrunal.github.io/posts/SciBERT-Transformer-for-Neuroscience/" /><meta property="og:site_name" content="Mrunal P. Gavali" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-14T00:00:00-07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="SciBERT Transformer for Neuroscience" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Mrunal"},"description":"Hugging Face Transformer model for Neuroscience JSON data","url":"https://gli-mrunal.github.io/posts/SciBERT-Transformer-for-Neuroscience/","@type":"BlogPosting","headline":"SciBERT Transformer for Neuroscience","dateModified":"2022-07-28T20:54:34-07:00","datePublished":"2022-07-14T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://gli-mrunal.github.io/posts/SciBERT-Transformer-for-Neuroscience/"},"@context":"https://schema.org"}</script><title>SciBERT Transformer for Neuroscience | Mrunal P. Gavali</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> // see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> MathJax = { tex: { inlineMath: [ // start/end delimiter pairs for in-line math ['$','$'], ['\\(','\\)'] ], displayMath: [ // start/end delimiter pairs for display math ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/Images/GSoC_img/i_1.PNG" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Mrunal P. Gavali</a></div><div class="site-subtitle font-italic">My GSoC'22 Blog</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/gli-mrunal" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/gli-mrunal" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>SciBERT Transformer for Neuroscience</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>SciBERT Transformer for Neuroscience</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Mrunal </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Jul 14, 2022, 12:00 AM -0700" prep="on" > Jul 14 <i class="unloaded">2022-07-14T00:00:00-07:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Thu, Jul 28, 2022, 8:54 PM -0700" prefix="Updated " > Jul 28 <i class="unloaded">2022-07-28T20:54:34-07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2041 words">11 min</span></div></div><div class="post-content"><h2 id="hugging-face-transformer-model-for-neuroscience-json-data">Hugging Face Transformer model for Neuroscience JSON data</h2><p>The objective of the project is to apply pretrained SciBERT transformer model and Cosine Similarity for recommending reviewers who have published neuroscience research papers on semantically similar research topic as the user’s input abstract query.</p><p><strong>Overall Approach</strong></p><ol><li>Load the pretrained SciBert model and tokenizer<li>Vectorize documents by creating embeddings<li>Semantic Similarity search by Cosine Similarity</ol><p>For the purpose of creating embeddings, the bioRxiv Neuroscience data is used.</p><h2 id="step-1--import-libraries">Step 1 : Import Libraries:</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Hugging Face Transformer libraries
</span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span>  <span class="n">AutoModelForSequenceClassification</span>

<span class="c1"># Similarity search: cosine similarity search 
</span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">"ignore"</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="step-2-load-the-biorxiv-neuroscience-data-in-json-format">Step 2: load the bioRxiv Neuroscience data in JSON format</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_json</span><span class="p">(</span><span class="s">"bioarxiv_parsed.json"</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="s">"Data Shape: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>

</pre></table></code></div></div><h2 id="step-3-load-pretrained-scibert-model-and-tokenizer">Step 3: Load Pretrained SciBERT model and tokenizer</h2><p>The SciBERT model is used for creating embeddings for the abstracts in the Neuroscience research papers. Note that in the code snippet below the <code class="language-plaintext highlighter-rouge">output_hidden_states</code> is set to <code class="language-plaintext highlighter-rouge">True</code> so that we can extract the embeddings.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># Get the SciBERT pretrained model path from Allen AI repo
</span><span class="n">pretrained_model</span> <span class="o">=</span> <span class="s">'allenai/scibert_scivocab_uncased'</span>

<span class="c1"># Get the tokenizer from the previous path
</span><span class="n">sciBERT_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">,</span> 
                                          <span class="n">do_lower_case</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Get the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">,</span>
                                                          <span class="n">output_attentions</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                                          <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><blockquote><p>model.eval() gives the architecture of the model as seen below:</p></blockquote><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
</pre><td class="rouge-code"><pre><span class="n">BertForSequenceClassification</span><span class="p">(</span>
  <span class="p">(</span><span class="n">bert</span><span class="p">):</span> <span class="n">BertModel</span><span class="p">(</span>
    <span class="p">(</span><span class="n">embeddings</span><span class="p">):</span> <span class="n">BertEmbeddings</span><span class="p">(</span>
      <span class="p">(</span><span class="n">word_embeddings</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">31090</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="p">(</span><span class="n">position_embeddings</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
      <span class="p">(</span><span class="n">token_type_embeddings</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
      <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">encoder</span><span class="p">):</span> <span class="n">BertEncoder</span><span class="p">(</span>
      <span class="p">(</span><span class="n">layer</span><span class="p">):</span> <span class="n">ModuleList</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="n">BertLayer</span><span class="p">(</span>
          <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">BertAttention</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="n">BertSelfAttention</span><span class="p">(</span>
              <span class="p">(</span><span class="n">query</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">value</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertSelfOutput</span><span class="p">(</span>
              <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
              <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="p">)</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">intermediate</span><span class="p">):</span> <span class="n">BertIntermediate</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">intermediate_act_fn</span><span class="p">):</span> <span class="n">GELUActivation</span><span class="p">()</span>
          <span class="p">)</span>
          <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">BertOutput</span><span class="p">(</span>
            <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">LayerNorm</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">768</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">pooler</span><span class="p">):</span> <span class="n">BertPooler</span><span class="p">(</span>
      <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">activation</span><span class="p">):</span> <span class="n">Tanh</span><span class="p">()</span>
    <span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">(</span><span class="n">classifier</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="p">)</span>

</pre></table></code></div></div><h2 id="step-4-create-an-embedding-for-a-given-text-data-using-scibert-pre-trained-model">Step 4: Create an embedding for a given text data using SciBERT pre-trained model</h2><p>This function <code class="language-plaintext highlighter-rouge">convert_single_abstract_to_embedding</code> is mostly inspired by the BERT Word Embeddings Tutorial of <a href="https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#3-extracting-embeddings">Chris McCormick</a> and <a href="https://towardsdatascience.com/scientific-documents-similarity-search-with-deep-learning-using-transformers-scibert-d47c4e501590">Zoumana Keita</a>. It aims to create an embedding for a given text data using a pre-trained model.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">convert_single_abstract_to_embedding</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">in_text</span><span class="p">,</span> <span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">510</span><span class="p">):</span>
    
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span>
                        <span class="n">in_text</span><span class="p">,</span> 
                        <span class="n">add_special_tokens</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> 
                        <span class="n">max_length</span> <span class="o">=</span> <span class="n">MAX_LEN</span><span class="p">,</span>                           
                   <span class="p">)</span>    

    <span class="n">results</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">([</span><span class="n">input_ids</span><span class="p">],</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"long"</span><span class="p">,</span> 
                              <span class="n">truncating</span><span class="o">=</span><span class="s">"post"</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">"post"</span><span class="p">)</span>
    
    <span class="c1"># Remove the outer list.
</span>    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Create attention masks    
</span>    <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
    
    <span class="c1"># Convert to tensors.
</span>    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">)</span>

    <span class="c1"># Add an extra dimension for the "batch" (even though there is only one 
</span>    <span class="c1"># input in this batch.)
</span>    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Put the model in "evaluation" mode, meaning feed-forward operation.
</span>    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

 
    <span class="c1"># Run the text through BERT, and collect all of the hidden states produced
</span>    <span class="c1"># from all 12 layers. 
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>        
        <span class="n">logits</span><span class="p">,</span> <span class="n">encoded_layers</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
                                    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">,</span> 
                                    <span class="n">token_type_ids</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> 
                                    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">,</span>
                                    <span class="n">return_dict</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="n">layer_i</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># The last BERT layer before the classifier.
</span>    <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># Only one input in the batch.
</span>    <span class="n">token_i</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># The first token, corresponding to [CLS]
</span>        
    <span class="c1"># Extract the embedding.
</span>    <span class="n">embedding</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="n">layer_i</span><span class="p">][</span><span class="n">batch_i</span><span class="p">][</span><span class="n">token_i</span><span class="p">]</span>

    <span class="c1"># Move to the CPU and convert to numpy ndarray.
</span>    <span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">return</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
    
</pre></table></code></div></div><p>Now we can use the model and tokenizer to generate an embedding for the 3rd input_abstract as a way of testing as seen in the code snippet below:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>    <span class="kn">from</span> <span class="nn">keras_preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>

    <span class="n">input_abstract</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">abstract</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

    <span class="n">abstract_embedding</span> <span class="o">=</span> <span class="n">convert_single_abstract_to_embedding</span><span class="p">(</span><span class="n">sciBERT_tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">input_abstract</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'Embedding shape: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">abstract_embedding</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
    
</pre></table></code></div></div><p>Note to run the above code snippet make sure you have installed keras and tensorflow. You can install both of them in the jupyter notebook in the following way:</p><div class="language-sh highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>    <span class="o">!</span>pip <span class="nb">install </span>keras
    
    <span class="o">!</span>pip3 <span class="nb">install </span>tensorflow
</pre></table></code></div></div><p>The output of the 3rd input abstract embedding shape is:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>    Embedding shape: (768,)
    Embedding is composed of 768 values.
</pre></table></code></div></div><h2 id="step-5-create-embedding-for-all-the-abstracts">Step 5: Create Embedding for all the abstracts</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre>   <span class="k">def</span> <span class="nf">convert_all_abstract_text_to_embedding</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    
    <span class="c1"># The list of all the embeddings
</span>    <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Get overall text data
</span>    <span class="n">overall_text_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">abstract</span><span class="p">.</span><span class="n">values</span>
    
    <span class="c1"># Loop over all the comment and get the embeddings
</span>    <span class="k">for</span> <span class="n">abstract</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">overall_text_data</span><span class="p">):</span>
        
        <span class="c1"># Get the embedding 
</span>        <span class="n">embedding</span> <span class="o">=</span> <span class="n">convert_single_abstract_to_embedding</span><span class="p">(</span><span class="n">sciBERT_tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">abstract</span><span class="p">)</span>
        
        <span class="c1">#add it to the list
</span>        <span class="n">embeddings</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
        
    <span class="k">print</span><span class="p">(</span><span class="s">"Conversion Done!"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">embeddings</span>
</pre></table></code></div></div><p>Note that creating embeddings for all the abstracts in the 3948 BioRxiv Neuroscience research papers takes atleast 2 hours in aws sagemaker.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>   <span class="c1"># This task can take a lot of time depending on the sample_size value 
</span>   <span class="n">embeddings</span> <span class="o">=</span> <span class="n">convert_all_abstract_text_to_embedding</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="step-6-save-the-embeddings-for-future-use">Step 6: Save the embeddings for future use</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>   
   <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
   <span class="n">np</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">'embeddings.npy'</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="step-7-load-the-saved-npy-embeddings">Step 7: Load the saved .npy embeddings</h2><pre><code class="language-pyhton">   embeddings = np.load('embeddings.npy')
</code></pre><h2 id="step-8-create-a-new-column-that-will-contain-embedding-of-each-body-text">Step 8: Create a new column that will contain embedding of each body text</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>   
<span class="k">def</span> <span class="nf">create_final_embeddings</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">):</span>
    
    <span class="n">df</span><span class="p">[</span><span class="s">"embeddings"</span><span class="p">]</span> <span class="o">=</span> <span class="n">embeddings</span>
    <span class="n">df</span><span class="p">[</span><span class="s">"embeddings"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"embeddings"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">emb</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">emb</span><span class="p">))</span>
    <span class="n">df</span><span class="p">[</span><span class="s">"embeddings"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"embeddings"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">emb</span><span class="p">:</span> <span class="n">emb</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">df</span>
    
</pre></table></code></div></div><p>To see the output:</p><pre><code class="language-pyhton">    data = create_final_embeddings(data, embeddings)
    data.head(3)
</code></pre><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="\Images\GSoC_img\emb.png" alt="embeddigns column" /></p><h2 id="references">References</h2><ol><li><p>@inproceedings{beltagy-etal-2019-scibert, title = “SciBERT: A Pretrained Language Model for Scientific Text”, author = “Beltagy, Iz and Lo, Kyle and Cohan, Arman”, booktitle = “EMNLP”, year = “2019”, publisher = “Association for Computational Linguistics”, url = “https://www.aclweb.org/anthology/D19-1371” }</p><li><p>@article{johnson2019billion, title={Billion-scale similarity search with {GPUs}}, author={Johnson, Jeff and Douze, Matthijs and J{'e}gou, Herv{'e}}, journal={IEEE Transactions on Big Data}, volume={7}, number={3}, pages={535–547}, year={2019}, publisher={IEEE} }</p><li><p>“Bert Word Embeddings Tutorial.” BERT Word Embeddings Tutorial · Chris McCormick, 14 May 2019, https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#3-extracting-embeddings.</p><li><p>Keita, Zoumana. “Scientific Documents Similarity Search with Deep Learning Using Transformers (Scibert).” Medium, Towards Data Science, 17 Jan. 2022, https://towardsdatascience.com/scientific-documents-similarity-search-with-deep-learning-using-transformers-scibert-d47c4e501590.</p><li><p>@article{Beltagy2020Longformer, title={Longformer: The Long-Document Transformer}, author={Iz Beltagy and Matthew E. Peters and Arman Cohan}, journal={arXiv:2004.05150}, year={2020}, }</p></ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/gsoc-blogging/'>GSoC Blogging</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/gsoc/" class="post-tag no-text-decoration" >GSoC</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://gli-mrunal.github.io/posts/SciBERT-Transformer-for-Neuroscience/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Hola-GSoC-2022/">Hola GSoC 2022!</a><li><a href="/posts/GSoC-2022-Final-Report/">GSoC 2022 Final Report</a><li><a href="/posts/PubMed-Data/">PubMed Data</a><li><a href="/posts/SciBERT-Transformer-for-Neuroscience/">SciBERT Transformer for Neuroscience</a><li><a href="/posts/Vector-Similarity-Search/">Vector Similarity Search</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/gsoc/">GSoC</a> <a class="post-tag" href="/tags/evaluation/">Evaluation</a> <a class="post-tag" href="/tags/report/">Report</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/PubMed-Data/"><div class="card-body"> <span class="timeago small" > Jun 26 <i class="unloaded">2022-06-26T00:00:00-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PubMed Data</h3><div class="text-muted small"><p> Automation for Pubmed XML data retrieval using E-utility Data Data is colelcted from the Pubmed Medline, Arxiv and Bioarxiv journals for neuroscience papers published for the past 5 years. The fi...</p></div></div></a></div><div class="card"> <a href="/posts/Hola-GSoC-2022/"><div class="card-body"> <span class="timeago small" > Jun 16 <i class="unloaded">2022-06-16T00:00:00-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Hola GSoC 2022!</h3><div class="text-muted small"><p> NLP is awesome. Beginning of GSoC 2022! I recently came to know the Google’s Summer of Code program which runs in summer. I loved the idea of contributing to the open source community. Motivatio...</p></div></div></a></div><div class="card"> <a href="/posts/Vector-Similarity-Search/"><div class="card-body"> <span class="timeago small" > Jul 21 <i class="unloaded">2022-07-21T00:00:00-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Vector Similarity Search</h3><div class="text-muted small"><p> Vector Similarity Search BERT (Bidirectional Encoder Representations from Transformers) is the most popular deep learning model in natural language processing field. Through 12 encoder layers, BER...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/PubMed-Data/" class="btn btn-outline-primary" prompt="Older"><p>PubMed Data</p></a> <a href="/posts/Vector-Similarity-Search/" class="btn btn-outline-primary" prompt="Newer"><p>Vector Similarity Search</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/gli-mrunal">Mrunal Gavali</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."> Some rights reserved. </span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/gsoc/">GSoC</a> <a class="post-tag" href="/tags/evaluation/">Evaluation</a> <a class="post-tag" href="/tags/report/">Report</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://gli-mrunal.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
