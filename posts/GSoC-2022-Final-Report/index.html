<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="GSoC 2022 Final Report" /><meta name="author" content="Mrunal Gavali" /><meta property="og:locale" content="en_US" /><meta name="description" content="Google Summer of Code 2022: Final Report In this post, I will share my GSoC’22 journey with the INCF organization on the project Automatic reviewer matching using Natural Language Processing: Infrastructure for NBDT Journal mentored by Dr. Konrad Kording, Dr.Titipat Achakulvisut, Dr.Daniele Marinazzo." /><meta property="og:description" content="Google Summer of Code 2022: Final Report In this post, I will share my GSoC’22 journey with the INCF organization on the project Automatic reviewer matching using Natural Language Processing: Infrastructure for NBDT Journal mentored by Dr. Konrad Kording, Dr.Titipat Achakulvisut, Dr.Daniele Marinazzo." /><link rel="canonical" href="https://gli-mrunal.github.io/posts/GSoC-2022-Final-Report/" /><meta property="og:url" content="https://gli-mrunal.github.io/posts/GSoC-2022-Final-Report/" /><meta property="og:site_name" content="Mrunal P. Gavali" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-08-23T00:00:00-07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="GSoC 2022 Final Report" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Mrunal Gavali"},"description":"Google Summer of Code 2022: Final Report In this post, I will share my GSoC’22 journey with the INCF organization on the project Automatic reviewer matching using Natural Language Processing: Infrastructure for NBDT Journal mentored by Dr. Konrad Kording, Dr.Titipat Achakulvisut, Dr.Daniele Marinazzo.","url":"https://gli-mrunal.github.io/posts/GSoC-2022-Final-Report/","@type":"BlogPosting","headline":"GSoC 2022 Final Report","dateModified":"2022-09-26T04:23:08-07:00","datePublished":"2022-08-23T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://gli-mrunal.github.io/posts/GSoC-2022-Final-Report/"},"@context":"https://schema.org"}</script><title>GSoC 2022 Final Report | Mrunal P. Gavali</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/Images/GSoC_img/i_1.PNG" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Mrunal P. Gavali</a></div><div class="site-subtitle font-italic">My GSoC'22 Blog</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/gli-mrunal" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/gli-mrunal" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>GSoC 2022 Final Report</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>GSoC 2022 Final Report</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Mrunal Gavali </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Aug 23, 2022, 12:00 AM -0700" prep="on" > Aug 23 <i class="unloaded">2022-08-23T00:00:00-07:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Sep 26, 2022, 4:23 AM -0700" prefix="Updated " > Sep 26 <i class="unloaded">2022-09-26T04:23:08-07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3914 words">21 min</span></div></div><div class="post-content"><h2 id="google-summer-of-code-2022-final-report">Google Summer of Code 2022: Final Report</h2><p>In this post, I will share my GSoC’22 journey with the INCF organization on the project <code class="language-plaintext highlighter-rouge">Automatic reviewer matching using Natural Language Processing: Infrastructure for NBDT Journal </code> mentored by <a href="https://www.linkedin.com/in/konrad-kording-7284044/">Dr. Konrad Kording</a>, <a href="https://www.linkedin.com/in/titipata/">Dr.Titipat Achakulvisut</a>, <a href="https://scholar.google.com/citations?user=OJbWSLoAAAAJ&amp;hl=en">Dr.Daniele Marinazzo</a>.</p><p>It was my first time participating in GSoC. I didn’t interact much on forums before. During GSoC, I contacted many people, raised issues, did pull requests, did code reviews and contributed to other open source projects. Now I have a better understanding of how software is developed in open source and how I can do my part in building more. I want to thank everyone who helped me in my open source journey.</p><h2 id="highlights">Highlights</h2><ul class="task-list"><li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Applied SciBERT to computational Neuroscience data.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Created BERT embeddings for abstracts.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Applied Cosine similarity semantic search for recommending reviewers in jupyter notebook.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Applied KNN using FAISS for semantic similarity search for recommending reviewers in jupyter notebook.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Developed Login and Authentication for Frontend web application using Typescript with Nextjs and Tailwindcss.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Using Docker for AI code development and runnning jupyter notebooks.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Building a Data Loaders for Computational Neuroscience data</ul><h2 id="important-links">Important Links</h2><ol><li><a href="https://summerofcode.withgoogle.com/programs/2022/projects/MDgaQFlg">The Project description for GSoC</a><li><a href="https://github.com/nbdt-journal/automatic-reviewer-assignment">GSoC’22 github Code repository</a><li><a href="https://github.com/nbdt-journal/automatic-reviewer-assignment/pull/14">PR #14</a> SciBERT Cosine Similarity<li><a href="https://github.com/nbdt-journal/automatic-reviewer-assignment/pull/8">PR #8</a> Client –&gt; login implemented for email authentication using firebase<li>Issue: <a href="https://github.com/nbdt-journal/automatic-reviewer-assignment/blob/parser_xml_to_csv/scripts/medline_parser/Medline_E-utility.ipynb">Pubmed XML data E-utility and automation in retreival</a> &amp; <a href="https://github.com/nbdt-journal/automatic-reviewer-assignment/tree/parser_module/data_loader">Data Loader</a></ol><h3 id="gsoc22-github-code-repository"><a href="https://github.com/nbdt-journal/automatic-reviewer-assignment">GSoC’22 github Code repository</a></h3><h2 id="in-progresss--todo">In Progresss / TODO</h2><ul class="task-list"><li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Dockerizing the entire application.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Scripting the jupyter notebooks.<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Integrating the AI application in the web application using Fastapi<li class="task-list-item" hide-bullet><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Deploy web app</ul><h2 id="usage-of-the-code-developed">Usage of the Code developed</h2><h3 id="running-data-loader">Running Data Loader</h3><p>We have created a Python library for retrieving scientific data from arXiv, bioRxiv, and MEDLINE using their respective APIs, and converting to a it format usable by the automatic reviewer recommendation algorithm.</p><p>Link: https://github.com/nbdt-journal/automatic-reviewer-assignment/tree/parser_module/data_loader</p><p>Usage To run the script, simply run:</p><div class="language-sh highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>  python3 main.py
</pre></table></code></div></div><p>To change the parameters of the function, you can simply change the values in config.yaml.The usage is self-described within the config file. If you wish to not use a certain data source for the parsing, set the parse value to false in the respective parser section.</p><h3 id="running-web-app">Running Web app</h3><p>Usage:</p><p>git clone the client branch of the repo and install the dependencies:</p><div class="language-bash highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="nb">cd </span>nbdt_frontend
<span class="nv">$ </span>npm <span class="nb">install</span>
<span class="nv">$ </span>npm run dev
</pre></table></code></div></div><h3 id="similarity-search-using-knn-with-faiss">Similarity Search Using KNN with Faiss</h3><p><code class="language-plaintext highlighter-rouge">Faiss</code> is a library developed by <a href="https://ai.facebook.com/">Facebook AI Research</a>. According to their <a href="https://github.com/facebookresearch/faiss/wiki">wikipage</a>,</p><p><code class="language-plaintext highlighter-rouge">Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM</code></p><p><strong>Here are the steps to build the search engine using the previously built embeddings</strong>:</p><ol><li>create the flat index: This is used to flat the vectors. The index uses the L2 (Euclidean) distance metrics to mesure the similarity betweeen the query vector and all the vectors (embeddings).<li>add all the vectors to the index<li>define the number K of similar document we want<li>run the similarity search</ol><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="\Images\GSoC_img\knn_1.png" alt="knn_1" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="\Images\GSoC_img\knn_2.png" alt="knn_2" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="\Images\GSoC_img\knn_3.png" alt="knn_3" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="\Images\GSoC_img\knn_4.png" alt="knn_4" /></p><p>Now change the above code into modular functions for KNN similarity search</p><ol><li>Perform query</ol><div class="language-sh highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>

def process_query<span class="o">(</span>query_text<span class="o">)</span>:
    <span class="s2">"""
    # Create a vector for given query and adjust it for cosine similarity search
    """</span>

    query_vect <span class="o">=</span> convert_single_abstract_to_embedding<span class="o">(</span>sciBERT_tokenizer, model, query_text<span class="o">)</span>
    query_vect <span class="o">=</span> np.array<span class="o">(</span>query_vect<span class="o">)</span>
    query_vect <span class="o">=</span> query_vect.reshape<span class="o">(</span>1, <span class="nt">-1</span><span class="o">)</span>
    <span class="k">return </span>query_vect
</pre></table></code></div></div><ol><li>KNN similarity search</ol><div class="language-sh highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
</pre><td class="rouge-code"><pre>def get_top_N_articles_knn<span class="o">(</span>query_text, data, <span class="nv">K</span><span class="o">=</span>10<span class="o">)</span>:
    <span class="s2">"""
    Retrieve K=10 articles similar to the query (smaller the L2 distance means more similarity and vice versa)
    """</span>
    query_vect <span class="o">=</span> process_query<span class="o">(</span>query_text<span class="o">)</span>
    revevant_cols <span class="o">=</span> <span class="o">[</span><span class="s2">"title"</span>, <span class="s2">"abstract"</span>,  <span class="s2">"doi"</span>, <span class="s2">"authors"</span>, <span class="s2">"source"</span>, <span class="s2">"cos_sim"</span><span class="o">]</span>
    
    <span class="c"># create the flat index to flat the vectors.</span>
    <span class="c"># The index uses the L2 (Euclidean) distance metrics to mesure the similarity betweeen </span>
    <span class="c"># the query vector and all the vectors (embeddings).</span>
    embedding_dimension <span class="o">=</span> len<span class="o">(</span>embeddings[0]<span class="o">)</span>
    indexFlatL2 <span class="o">=</span> faiss.IndexFlatL2<span class="o">(</span>embedding_dimension<span class="o">)</span>  <span class="c">#768 in this case</span>
    
    <span class="c"># Convert the embeddings list of vectors into a 2D array.</span>
    vectors <span class="o">=</span> np.stack<span class="o">(</span>embeddings<span class="o">)</span>
    indexFlatL2.add<span class="o">(</span>vectors<span class="o">)</span> <span class="c"># add all the vectors to the index </span>
    
    <span class="c"># Run the similarity query search</span>
    D, I <span class="o">=</span> indexFlatL2.search<span class="o">(</span>query_vector, K<span class="o">)</span>
    

    <span class="k">for </span>i <span class="k">in </span>range<span class="o">(</span>I.shape[1]<span class="o">)</span>:
    
        article_index <span class="o">=</span> I[0, i]
    
        abstract <span class="o">=</span> data.iloc[article_index].abstract
        print<span class="o">(</span><span class="s2">"** Article #{} **"</span>.format<span class="o">(</span>article_index<span class="o">))</span>
        print<span class="o">(</span><span class="s2">"** --&gt; Abstract : </span><span class="se">\n</span><span class="s2">{}**"</span>.format<span class="o">(</span>abstract<span class="o">))</span>
    
        authors <span class="o">=</span> data.iloc[article_index].authors
        print<span class="o">(</span><span class="s2">"** Authors: </span><span class="se">\n</span><span class="s2">{}**"</span>.format<span class="o">(</span>authors<span class="o">))</span>
    
        doi <span class="o">=</span> data.iloc[article_index].doi
        print<span class="o">(</span><span class="s2">"** DOI: </span><span class="se">\n</span><span class="s2">{}**"</span>.format<span class="o">(</span>doi<span class="o">))</span>
    
        <span class="nb">source</span> <span class="o">=</span> data.iloc[article_index].source
        print<span class="o">(</span><span class="s2">"** Source: </span><span class="se">\n</span><span class="s2">{} **"</span>.format<span class="o">(</span><span class="nb">source</span><span class="o">))</span>
    
    
    
        print<span class="o">(</span><span class="s2">"**---</span><span class="se">\n</span><span class="s2"> L2 Distance: %.2f </span><span class="se">\n</span><span class="s2"> ---**"</span> % D[0, i]<span class="o">)</span>
        print<span class="o">(</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span><span class="o">)</span>
        print<span class="o">(</span><span class="s2">"--------------------------------------------------------------------------------------------------------------------</span><span class="se">\n</span><span class="s2">"</span><span class="o">)</span>
</pre></table></code></div></div><hr /><p>Now, test on a abstract from data:</p><div class="language-sh highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>query_text_test <span class="o">=</span> data.iloc[0].abstract <span class="c"># query abstract input</span>

top_articles <span class="o">=</span> get_top_N_articles_knn<span class="o">(</span>query_text_test, data<span class="o">)</span> <span class="c"># 10 similar recommendations in descending order</span>
</pre></table></code></div></div><hr /><p>OR</p><ol><li>User input for customm query</ol><div class="language-sh highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>

query_text_test <span class="o">=</span> str<span class="o">(</span>input<span class="o">())</span>
<span class="c">#query_text_test = data.iloc[0].abstract # query abstract input</span>
print<span class="o">(</span><span class="s2">"--------------------------------------------------------------------------------------------------------------------</span><span class="se">\n</span><span class="s2">"</span><span class="o">)</span>
print<span class="o">(</span><span class="s2">"********************     RECOMMENDATIONS     *************</span><span class="se">\n</span><span class="s2">"</span><span class="o">)</span>

<span class="nv">top_articles</span><span class="o">=</span> get_top_N_articles_knn<span class="o">(</span>query_text, data<span class="o">)</span> <span class="c"># apply knn similarity search function</span>

<span class="c"># the recommendations are not for user input abstract</span>

</pre></table></code></div></div><p><strong>user input</strong>:</p><p><code class="language-plaintext highlighter-rouge">Cognition allows sensory experiences to inform later actions in flexible ways. A new study shows that, in a cognitively demanding task, monkeys store visual information in short-term memory and replay it when they need it to make a decision.</code></p><p><strong>Recommendations</strong>:</p><div class="language-sh highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
</pre><td class="rouge-code"><pre><span class="k">**</span> Article <span class="c">#0 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
To analyse neuron data at scale, neuroscientists expend substantial effort reading documentation, installing dependencies and moving between analysis and visualisation environments. To facilitate this, we have developed a suite of interoperable open-source R packages called the natverse. The natverse allows <span class="nb">users </span>to <span class="nb">read local </span>and remote data, perform popular analyses including visualisation, clustering and graph-theoretic analysis of neuronal branching. Unlike most tools, the natverse enables comparison of morphology and connectivity across many neurons after imaging or co-registration within a common template space. The natverse also enables transformations between different template spaces and imaging modalities. We demonstrate tools that integrate the vast majority of Drosophila neuroanatomical light microscopy and electron microscopy connectomic datasets. The natverse is an easy-to-use environment <span class="k">for </span>neuroscientists to solve complex, large-scale analysis challenges as well as an open platform to create new code and packages to share with the community.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Bates, A. S.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'Division of Neurobiology, MRC Laboratory of Molecular Biology, Cambridge, CB2?0QH, UK'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Manton, J. D.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'Division of Neurobiology, MRC Laboratory of Molecular Biology, Cambridge, CB2?0QH, UK'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Jagannathan, S. R.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'Division of Neurobiology, MRC Laboratory of Molecular Biology, Cambridge, CB2?0QH, UK'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Costa, M.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'Division of Neurobiology, MRC Laboratory of Molecular Biology, Cambridge, CB2?0QH, UK'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Schlegel, P.'</span>, <span class="s1">'number on Paper'</span>: 5, <span class="s1">'institution'</span>: <span class="s1">'Division of Neurobiology, MRC Laboratory of Molecular Biology, Cambridge, CB2?0QH, UK'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Rohlfing, T.'</span>, <span class="s1">'number on Paper'</span>: 6, <span class="s1">'institution'</span>: <span class="s1">'Division of Neurobiology, MRC Laboratory of Molecular Biology, Cambridge, CB2?0QH, UK'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Jefferis, G. S. X. E.'</span>, <span class="s1">'number on Paper'</span>: 7, <span class="s1">'institution'</span>: <span class="s1">'Division of Neurobiology, MRC Laboratory of Molecular Biology, Cambridge, CB2?0QH, UK'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/006353<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 0.00 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#779 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
Computational models are powerful tools <span class="k">for </span>investigating brain <span class="k">function in </span>health and disease. However, biologically detailed neuronal and circuit models are complex and implemented <span class="k">in </span>a range of specialized languages, making them inaccessible and opaque to many neuroscientists. This has limited critical evaluation of models by the scientific community and impeded their refinement and widespread adoption. To address this, we have combined advances <span class="k">in </span>standardizing models, open <span class="nb">source </span>software development and web technologies to develop Open Source Brain, a platform <span class="k">for </span>visualizing, simulating, disseminating and collaboratively developing standardized models of neurons and circuits from a range of brain regions. Model structure and parameters can be visualized and their dynamical properties explored through browser-controlled simulations, without writing code. Open Source Brain makes neural models transparent and accessible and facilitates testing, critical evaluation and refinement, thereby helping to improve the accuracy and reproducibility of models, and their dissemination to the wider community.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Gleeson, P.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Cantarelli, M.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Marin, B.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Quintana, A.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Earnshaw, M.'</span>, <span class="s1">'number on Paper'</span>: 5, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Piasini, E.'</span>, <span class="s1">'number on Paper'</span>: 6, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Birgiolas, J.'</span>, <span class="s1">'number on Paper'</span>: 7, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Cannon, R. C.'</span>, <span class="s1">'number on Paper'</span>: 8, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Cayco-Gajic, N. A.'</span>, <span class="s1">'number on Paper'</span>: 9, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Crook, S.'</span>, <span class="s1">'number on Paper'</span>: 10, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Davison, A. P.'</span>, <span class="s1">'number on Paper'</span>: 11, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Dura-Bernal, S.'</span>, <span class="s1">'number on Paper'</span>: 12, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Ecker, A.'</span>, <span class="s1">'number on Paper'</span>: 13, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Hines, M. L.'</span>, <span class="s1">'number on Paper'</span>: 14, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Idili, G.'</span>, <span class="s1">'number on Paper'</span>: 15, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Larson, S.'</span>, <span class="s1">'number on Paper'</span>: 16, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Lytton, W. W.'</span>, <span class="s1">'number on Paper'</span>: 17, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Majumdar, A.'</span>, <span class="s1">'number on Paper'</span>: 18, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' McDougal, R. A.'</span>, <span class="s1">'number on Paper'</span>: 19, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Sivagnanam, S.'</span>, <span class="s1">'number on Paper'</span>: 20, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Solinas, S.'</span>, <span class="s1">'number on Paper'</span>: 21, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Stanislovas, R.'</span>, <span class="s1">'number on Paper'</span>: 22, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' van Albada, S. J.'</span>, <span class="s1">'number on Paper'</span>: 23, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Van Geit, W.'</span>, <span class="s1">'number on Paper'</span>: 24, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Silver, R. A.'</span>, <span class="s1">'number on Paper'</span>: 25, <span class="s1">'institution'</span>: <span class="s1">'University College London'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/229484<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 105.82 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#282 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
Human neuroscience research faces several challenges with regards to reproducibility. While scientists are generally aware that data sharing is an important component of reproducible research, it is not always clear how to usefully share data <span class="k">in </span>a manner that allows other labs to understand and reproduce published findings. Here we describe a new open <span class="nb">source </span>tool, AFQ-Browser, that builds an interactive website as a companion to a published diffusion MRI study. Because AFQ-browser is portable <span class="nt">--</span> it runs <span class="k">in </span>any modern web-browser <span class="nt">--</span> it can facilitate transparency and data sharing. Moreover, by leveraging new web-visualization technologies to create linked views between different dimensions of a diffusion MRI dataset <span class="o">(</span>anatomy, quantitative diffusion metrics, subject metadata<span class="o">)</span>, AFQ-Browser facilitates exploratory data analysis, fueling new scientific discoveries based on previously published datasets. In an era where Big Data is playing an increasingly prominent role <span class="k">in </span>scientific discovery, so will browser-based tools <span class="k">for </span>exploring high-dimensional datasets, communicating scientific discoveries, sharing and aggregating data across labs, and publishing data alongside manuscripts.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Yeatman, J. D.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Richie-Halford, A.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Smith, J. K.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Keshavan, A.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Rokem, A.'</span>, <span class="s1">'number on Paper'</span>: 5, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/182402<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 108.02 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#281 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
Human neuroscience research faces several challenges with regards to reproducibility. While scientists are generally aware that data sharing is an important component of reproducible research, it is not always clear how to usefully share data <span class="k">in </span>a manner that allows other labs to understand and reproduce published findings. Here we describe a new open <span class="nb">source </span>tool, AFQ-Browser, that builds an interactive website as a companion to a published diffusion MRI study. Because AFQ-browser is portable <span class="nt">--</span> it runs <span class="k">in </span>any modern web-browser <span class="nt">--</span> it can facilitate transparency and data sharing. Moreover, by leveraging new web-visualization technologies to create linked views between different dimensions of a diffusion MRI dataset <span class="o">(</span>anatomy, quantitative diffusion metrics, subject metadata<span class="o">)</span>, AFQ-Browser facilitates exploratory data analysis, fueling new scientific discoveries based on previously published datasets. In an era where Big Data is playing an increasingly prominent role <span class="k">in </span>scientific discovery, so will browser-based tools <span class="k">for </span>exploring high-dimensional datasets, communicating scientific discoveries, sharing and aggregating data across labs, and publishing data alongside manuscripts.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Yeatman, J. D.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Richie-Halford, A.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Smith, J. K.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Keshavan, A.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Rokem, A.'</span>, <span class="s1">'number on Paper'</span>: 5, <span class="s1">'institution'</span>: <span class="s1">'The University of Washington'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/182402<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 108.02 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#3933 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
Modern neuroscience research often requires the coordination of multiple processes such as stimulus generation, real-time experimental control, as well as behavioral and neural measurements. The technical demands required to simultaneously manage these processes with high temporal fidelity limits the number of labs capable of performing such work. Here we present an open-source network-based parallel processing framework that eliminates these barriers. The Real-Time Experimental Control with Graphical User Interface <span class="o">(</span>REC-GUI<span class="o">)</span> framework offers multiple advantages: <span class="o">(</span>i<span class="o">)</span> a modular design agnostic to coding language<span class="o">(</span>s<span class="o">)</span> and operating system<span class="o">(</span>s<span class="o">)</span> that maximizes experimental flexibility and minimizes researcher effort, <span class="o">(</span>ii<span class="o">)</span> simple interfacing to connect measurement and recording devices, <span class="o">(</span>iii<span class="o">)</span> high temporal fidelity by dividing task demands across CPUs, and <span class="o">(</span>iv<span class="o">)</span> real-time control using a fully customizable and intuitive GUI. Testing results demonstrate that the REC-GUI framework facilitates technically demanding, behavior-contingent neuroscience research. Sample code and hardware configurations are downloadable, and future developments will be regularly released.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Kim, B.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'University of Wisconsin - Madison'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Kenchappa, S. C.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'University of Wisconsin - Madison'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Sunkara, A.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'University of Wisconsin - Madison'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Chang, T.-Y.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'University of Wisconsin - Madison'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Thompson, L.'</span>, <span class="s1">'number on Paper'</span>: 5, <span class="s1">'institution'</span>: <span class="s1">'University of Wisconsin - Madison'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Doudlah, R.'</span>, <span class="s1">'number on Paper'</span>: 6, <span class="s1">'institution'</span>: <span class="s1">'University of Wisconsin - Madison'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Rosenberg, A.'</span>, <span class="s1">'number on Paper'</span>: 7, <span class="s1">'institution'</span>: <span class="s1">'University of Wisconsin - Madison'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/392654<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 110.22 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#2440 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
Hyperspectral imaging is a widely used technology <span class="k">for </span>industrial and scientific purposes, but the high cost and large size of commercial setups have made them impractical <span class="k">for </span>most basic research. Here, we designed and implemented a fully open <span class="nb">source </span>and low-cost hyperspectral scanner based on a commercial spectrometer coupled to custom optical, mechanical and electronic components. We demonstrate our scanners utility <span class="k">for </span>natural imaging <span class="k">in </span>both terrestrial and underwater environments. Our design provides sub-nm spectral resolution between 350-1000 nm, including the UV part of the light spectrum which has been mostly absent from commercial solutions and previous natural imaging studies. By comparing the full light spectra from natural scenes to the spectral sensitivity of animals, we show how our system can be used to identify subtle variations <span class="k">in </span>chromatic details detectable by different species. In addition, we have created an open access database <span class="k">for </span>hyperspectral datasets collected from natural scenes <span class="k">in </span>the UK and India. Together with comprehensive online build- and use-instructions, our setup provides an inexpensive and customisable solution to gather and share hyperspectral imaging data.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Nevala, N. E.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'University of Sussex'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Baden, T.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'University of Sussex'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/322172<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 110.76 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#1801 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
Operant conditioning is a crucial tool <span class="k">in </span>neuroscience research <span class="k">for </span>probing brain <span class="k">function</span><span class="nb">.</span> While molecular, anatomical and even physiological techniques have seen radical increases <span class="k">in </span>throughput, efficiency, and reproducibility <span class="k">in </span>recent years, behavioural tools have seen much less of an improvement. Here we present a fully automated, high-throughput system <span class="k">for </span>self-initiated conditioning of up to 25 group-housed, radio-frequency identification <span class="o">(</span>RFID<span class="o">)</span> tagged mice over periods of several months and <span class="o">&gt;</span>10^6 trials. We validate this <span class="se">\"</span>AutonoMouse<span class="se">\"</span> system <span class="k">in </span>a series of olfactory behavioural tasks and show that acquired data is comparable to previous semi-manual approaches. Furthermore, we use AutonoMouse to systematically probe the impact of graded olfactory bulb lesions on olfactory behaviour and resolve the long-standing conundrum about the apparent lack of impact of lesions on olfactory abilities. The modular nature and open-source design of AutonoMouse should allow <span class="k">for </span>similar robust and systematic assessments across neuroscience research areas.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Erskine, A.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'The Francis Crick Institute'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Bus, T.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'The Francis Crick Institute'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Herb, J. T.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'The Francis Crick Institute'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Schaefer, A. T.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'The Francis Crick Institute'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/291815<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 117.73 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#1622 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
Alzheimers disease <span class="o">(</span>AD<span class="o">)</span> is a progressive neurodegenerative disorder that currently affects 36 million people worldwide with no effective treatment available. Development of AD follows a distinctive pattern <span class="k">in </span>the brain and is poorly modelled <span class="k">in </span>animals. Therefore, it is vital to widen both the spatial scope of the study of AD and prioritise the study of human brains. Here we show that functionally distinct human brain regions show varying and region-specific changes <span class="k">in </span>protein expression. These changes provide novel insights into the progression of disease, novel AD-related pathways, the presence of a  gradient of protein expression change from less to more affected regions, and the presence of a  protective protein expression profile <span class="k">in </span>the cerebellum. This spatial proteomics analysis provides a framework which can underpin current research and opens new avenues of interest to enhance our understanding of molecular pathophysiology of AD, provides new targets <span class="k">for </span>intervention and broadens the conceptual frameworks <span class="k">for </span>future AD research.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Xu, J.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Patassini, S.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Rustogi, N.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Riba-Garcia, I.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Hale, B. D.'</span>, <span class="s1">'number on Paper'</span>: 5, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Phillips, A. M.'</span>, <span class="s1">'number on Paper'</span>: 6, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Waldvogel, H.'</span>, <span class="s1">'number on Paper'</span>: 7, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Haines, R.'</span>, <span class="s1">'number on Paper'</span>: 8, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Bradbury, P.'</span>, <span class="s1">'number on Paper'</span>: 9, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Stevens, A.'</span>, <span class="s1">'number on Paper'</span>: 10, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Faull, R. L.'</span>, <span class="s1">'number on Paper'</span>: 11, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Dowsey, A. W.'</span>, <span class="s1">'number on Paper'</span>: 12, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Cooper, G. J.'</span>, <span class="s1">'number on Paper'</span>: 13, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Unwin, R.'</span>, <span class="s1">'number on Paper'</span>: 14, <span class="s1">'institution'</span>: <span class="s1">'The University of Manchester'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/283705<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 119.27 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#1203 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
It is widely assumed that cells must be physically isolated to study their molecular profiles. However, intact tissue samples naturally exhibit variation <span class="k">in </span>cellular composition, which drives covariation of cell-class-specific molecular features. By analyzing transcriptional covariation <span class="k">in </span>7221 intact CNS samples from 840 individuals representing billions of cells, we reveal the core transcriptional identities of major CNS cell classes <span class="k">in </span>humans. By modeling intact CNS transcriptomes as a <span class="k">function </span>of variation <span class="k">in </span>cellular composition, we identify cell-class-specific transcriptional differences <span class="k">in </span>Alzheimers disease, among brain regions, and between species. Among these, we show that PMP2 is expressed by human but not mouse astrocytes and significantly increases mouse astrocyte size upon ectopic expression <span class="k">in </span>vivo, causing them to more closely resemble their human counterparts. Our work is available as an online resource <span class="o">(</span>http://oldhamlab.ctec.ucsf.edu<span class="o">)</span> and provides a generalizable strategy <span class="k">for </span>determining the core molecular features of cellular identity <span class="k">in </span>intact biological systems.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Kelley, K. W.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'University of California, San Francisco'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Inoue, H.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'University of California, San Francisco'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Molofsky, A. V.'</span>, <span class="s1">'number on Paper'</span>: 3, <span class="s1">'institution'</span>: <span class="s1">'University of California, San Francisco'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Oldham, M. C.'</span>, <span class="s1">'number on Paper'</span>: 4, <span class="s1">'institution'</span>: <span class="s1">'University of California, San Francisco'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/265397<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 125.81 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>

<span class="k">**</span> Article <span class="c">#1131 **</span>
<span class="k">**</span> <span class="nt">--</span><span class="o">&gt;</span> Abstract : 
The interpretation of neuronal spike train recordings often relies on abstract statistical models that allow <span class="k">for </span>principled parameter estimation and model selection but provide only limited insights into underlying microcircuits. In contrast, mechanistic models are useful to interpret microcircuit dynamics, but are rarely quantitatively matched to experimental data due to methodological challenges. Here we present analytical methods to efficiently fit spiking circuit models to single-trial spike trains. Using derived likelihood functions, we statistically infer the mean and variance of hidden inputs, neuronal adaptation properties and connectivity <span class="k">for </span>coupled integrate-and-fire neurons. Comprehensive evaluations on synthetic data, validations using ground truth <span class="k">in</span><span class="nt">-vitro</span> and <span class="k">in</span><span class="nt">-vivo</span> recordings, and comparisons with existing techniques demonstrate that parameter estimation is very accurate and efficient, even <span class="k">for </span>highly subsampled networks. Our methods bridge statistical, data-driven and theoretical, model-based neurosciences at the level of spiking circuits, <span class="k">for </span>the purpose of a quantitative, mechanistic interpretation of recorded neuronal population activity.<span class="k">**</span>
<span class="k">**</span> Authors: 
<span class="o">[{</span><span class="s1">'author'</span>: <span class="s1">'Ladenbauer, J.'</span>, <span class="s1">'number on Paper'</span>: 1, <span class="s1">'institution'</span>: <span class="s1">'Technische Universität Berlin'</span><span class="o">}</span>, <span class="o">{</span><span class="s1">'author'</span>: <span class="s1">' Ostojic, S.'</span>, <span class="s1">'number on Paper'</span>: 2, <span class="s1">'institution'</span>: <span class="s1">'Technische Universität Berlin'</span><span class="o">}]</span><span class="k">**</span>
<span class="k">**</span> DOI: 
10.1101/261016<span class="k">**</span>
<span class="k">**</span> Source: 
bioarxiv <span class="k">**</span>
<span class="k">**</span><span class="nt">---</span>
 L2 Distance: 130.74 
 <span class="nt">---</span><span class="k">**</span>



<span class="nt">--------------------------------------------------------------------------------------------------------------------</span>
</pre></table></code></div></div><p><strong>Observation</strong></p><ul><li>The lower the distance is, the most similar the article is to the query.<li>The first document has L2 = 0, which means 100% similarity. This is obvious, because the query was compared with itself.<li>We can simply remove it to the analysis.</ul><p>Note: Refer to <a href="https://gli-mrunal.github.io/posts/Docker/">my GSoC blog</a> for docker setup for AI.</p><p><strong>GoodBye!</strong></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/gsoc-blogging/'>GSoC Blogging</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/nlp/" class="post-tag no-text-decoration" >NLP</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://gli-mrunal.github.io/posts/GSoC-2022-Final-Report/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Hola-GSoC-2022/">Hola GSoC 2022!</a><li><a href="/posts/GSoC-2022-Final-Report/">GSoC 2022 Final Report</a><li><a href="/posts/PubMed-Data/">PubMed Data</a><li><a href="/posts/SciBERT-Transformer-for-Neuroscience/">SciBERT Transformer for Neuroscience</a><li><a href="/posts/Vector-Similarity-Search/">Vector Similarity Search</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/gsoc/">GSoC</a> <a class="post-tag" href="/tags/evaluation/">Evaluation</a> <a class="post-tag" href="/tags/report/">Report</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Hola-GSoC-2022/"><div class="card-body"> <span class="timeago small" > Jun 16 <i class="unloaded">2022-06-16T00:00:00-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Hola GSoC 2022!</h3><div class="text-muted small"><p> NLP is awesome. Beginning of GSoC 2022! I recently came to know the Google’s Summer of Code program which runs in summer. I loved the idea of contributing to the open source community. Motivatio...</p></div></div></a></div><div class="card"> <a href="/posts/Vector-Similarity-Search/"><div class="card-body"> <span class="timeago small" > Jul 21 <i class="unloaded">2022-07-21T00:00:00-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Vector Similarity Search</h3><div class="text-muted small"><p> Vector Similarity Search BERT (Bidirectional Encoder Representations from Transformers) is the most popular deep learning model in natural language processing field. Through 12 encoder layers, BER...</p></div></div></a></div><div class="card"> <a href="/posts/Docker/"><div class="card-body"> <span class="timeago small" > Aug 18 <i class="unloaded">2022-08-18T00:00:00-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Docker for AI</h3><div class="text-muted small"><p> Docker for AI DOCKER Installation and Setup in ubuntu 20.04 Docker install in ubuntu follwoing this reference. The commands are copied to below in the order with one change in the last step. ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Docker/" class="btn btn-outline-primary" prompt="Older"><p>Docker for AI</p></a> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/gli-mrunal">Mrunal Gavali</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."> Some rights reserved. </span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/gsoc/">GSoC</a> <a class="post-tag" href="/tags/evaluation/">Evaluation</a> <a class="post-tag" href="/tags/report/">Report</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://gli-mrunal.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
